{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "111                6.4               2.7                5.3               1.9   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "98                 5.1               2.5                3.0               1.1   \n",
       "119                6.0               2.2                5.0               1.5   \n",
       "46                 5.1               3.8                1.6               0.2   \n",
       "80                 5.5               2.4                3.8               1.1   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "93                 5.0               2.3                3.3               1.0   \n",
       "106                4.9               2.5                4.5               1.7   \n",
       "\n",
       "     species  \n",
       "111        2  \n",
       "128        2  \n",
       "98         1  \n",
       "119        2  \n",
       "46         0  \n",
       "80         1  \n",
       "120        2  \n",
       "146        2  \n",
       "93         1  \n",
       "106        2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['species'] = data.target\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.input_layer = nn.Linear(4, 100)\n",
    "        self.hidden_layer = nn.Linear(100, 100)\n",
    "        self.output_layer = nn.Linear(100, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.input_layer(X))\n",
    "        X = self.hidden_layer(X)\n",
    "        X = self.output_layer(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(df[df.columns[0:4]].values,\n",
    "                                                    df.species.values, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap up with Variable in pytorch\n",
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 1.096192717552185\n",
      "Epoch: 1 \tLoss: 1.0863816738128662\n",
      "Epoch: 2 \tLoss: 1.0780764818191528\n",
      "Epoch: 3 \tLoss: 1.0710769891738892\n",
      "Epoch: 4 \tLoss: 1.0651626586914062\n",
      "Epoch: 5 \tLoss: 1.0601344108581543\n",
      "Epoch: 6 \tLoss: 1.055821418762207\n",
      "Epoch: 7 \tLoss: 1.0520800352096558\n",
      "Epoch: 8 \tLoss: 1.0487868785858154\n",
      "Epoch: 9 \tLoss: 1.0458414554595947\n",
      "Epoch: 10 \tLoss: 1.0431610345840454\n",
      "Epoch: 11 \tLoss: 1.0406774282455444\n",
      "Epoch: 12 \tLoss: 1.0383378267288208\n",
      "Epoch: 13 \tLoss: 1.0361013412475586\n",
      "Epoch: 14 \tLoss: 1.0339369773864746\n",
      "Epoch: 15 \tLoss: 1.03182053565979\n",
      "Epoch: 16 \tLoss: 1.0297343730926514\n",
      "Epoch: 17 \tLoss: 1.0276660919189453\n",
      "Epoch: 18 \tLoss: 1.0256073474884033\n",
      "Epoch: 19 \tLoss: 1.0235521793365479\n",
      "Epoch: 20 \tLoss: 1.0214954614639282\n",
      "Epoch: 21 \tLoss: 1.019434928894043\n",
      "Epoch: 22 \tLoss: 1.017369031906128\n",
      "Epoch: 23 \tLoss: 1.015297293663025\n",
      "Epoch: 24 \tLoss: 1.0132197141647339\n",
      "Epoch: 25 \tLoss: 1.0111361742019653\n",
      "Epoch: 26 \tLoss: 1.0090473890304565\n",
      "Epoch: 27 \tLoss: 1.006954550743103\n",
      "Epoch: 28 \tLoss: 1.0048588514328003\n",
      "Epoch: 29 \tLoss: 1.0027605295181274\n",
      "Epoch: 30 \tLoss: 1.0006622076034546\n",
      "Epoch: 31 \tLoss: 0.9985644221305847\n",
      "Epoch: 32 \tLoss: 0.9964680075645447\n",
      "Epoch: 33 \tLoss: 0.994374692440033\n",
      "Epoch: 34 \tLoss: 0.9922854900360107\n",
      "Epoch: 35 \tLoss: 0.9902023077011108\n",
      "Epoch: 36 \tLoss: 0.9881253838539124\n",
      "Epoch: 37 \tLoss: 0.9860568642616272\n",
      "Epoch: 38 \tLoss: 0.9839967489242554\n",
      "Epoch: 39 \tLoss: 0.9819466471672058\n",
      "Epoch: 40 \tLoss: 0.9799075722694397\n",
      "Epoch: 41 \tLoss: 0.9778805375099182\n",
      "Epoch: 42 \tLoss: 0.9758668541908264\n",
      "Epoch: 43 \tLoss: 0.9738667607307434\n",
      "Epoch: 44 \tLoss: 0.971881091594696\n",
      "Epoch: 45 \tLoss: 0.9699103236198425\n",
      "Epoch: 46 \tLoss: 0.9679555296897888\n",
      "Epoch: 47 \tLoss: 0.9660166501998901\n",
      "Epoch: 48 \tLoss: 0.9640945196151733\n",
      "Epoch: 49 \tLoss: 0.9621900916099548\n",
      "Epoch: 50 \tLoss: 0.9603040814399719\n",
      "Epoch: 51 \tLoss: 0.9584360718727112\n",
      "Epoch: 52 \tLoss: 0.9565861821174622\n",
      "Epoch: 53 \tLoss: 0.9547548890113831\n",
      "Epoch: 54 \tLoss: 0.9529425501823425\n",
      "Epoch: 55 \tLoss: 0.951149582862854\n",
      "Epoch: 56 \tLoss: 0.9493747353553772\n",
      "Epoch: 57 \tLoss: 0.947618842124939\n",
      "Epoch: 58 \tLoss: 0.9458828568458557\n",
      "Epoch: 59 \tLoss: 0.9441656470298767\n",
      "Epoch: 60 \tLoss: 0.9424690008163452\n",
      "Epoch: 61 \tLoss: 0.9407920241355896\n",
      "Epoch: 62 \tLoss: 0.9391350746154785\n",
      "Epoch: 63 \tLoss: 0.9374977350234985\n",
      "Epoch: 64 \tLoss: 0.9358794093132019\n",
      "Epoch: 65 \tLoss: 0.9342814683914185\n",
      "Epoch: 66 \tLoss: 0.932702898979187\n",
      "Epoch: 67 \tLoss: 0.9311437010765076\n",
      "Epoch: 68 \tLoss: 0.9296041131019592\n",
      "Epoch: 69 \tLoss: 0.9280835390090942\n",
      "Epoch: 70 \tLoss: 0.9265819787979126\n",
      "Epoch: 71 \tLoss: 0.9250990152359009\n",
      "Epoch: 72 \tLoss: 0.9236351847648621\n",
      "Epoch: 73 \tLoss: 0.9221892356872559\n",
      "Epoch: 74 \tLoss: 0.9207616448402405\n",
      "Epoch: 75 \tLoss: 0.9193519353866577\n",
      "Epoch: 76 \tLoss: 0.9179601073265076\n",
      "Epoch: 77 \tLoss: 0.9165855646133423\n",
      "Epoch: 78 \tLoss: 0.9152281880378723\n",
      "Epoch: 79 \tLoss: 0.9138878583908081\n",
      "Epoch: 80 \tLoss: 0.9125643968582153\n",
      "Epoch: 81 \tLoss: 0.911257266998291\n",
      "Epoch: 82 \tLoss: 0.909966766834259\n",
      "Epoch: 83 \tLoss: 0.9086920022964478\n",
      "Epoch: 84 \tLoss: 0.9074332118034363\n",
      "Epoch: 85 \tLoss: 0.9061899781227112\n",
      "Epoch: 86 \tLoss: 0.9049620032310486\n",
      "Epoch: 87 \tLoss: 0.903749406337738\n",
      "Epoch: 88 \tLoss: 0.902551531791687\n",
      "Epoch: 89 \tLoss: 0.9013680219650269\n",
      "Epoch: 90 \tLoss: 0.9001989364624023\n",
      "Epoch: 91 \tLoss: 0.8990439772605896\n",
      "Epoch: 92 \tLoss: 0.8979028463363647\n",
      "Epoch: 93 \tLoss: 0.8967758417129517\n",
      "Epoch: 94 \tLoss: 0.8956629633903503\n",
      "Epoch: 95 \tLoss: 0.8945631384849548\n",
      "Epoch: 96 \tLoss: 0.8934755325317383\n",
      "Epoch: 97 \tLoss: 0.8924006819725037\n",
      "Epoch: 98 \tLoss: 0.8913381099700928\n",
      "Epoch: 99 \tLoss: 0.8902880549430847\n",
      "Epoch: 100 \tLoss: 0.8892500400543213\n",
      "Epoch: 101 \tLoss: 0.8882240056991577\n",
      "Epoch: 102 \tLoss: 0.8872098922729492\n",
      "Epoch: 103 \tLoss: 0.8862070441246033\n",
      "Epoch: 104 \tLoss: 0.8852155804634094\n",
      "Epoch: 105 \tLoss: 0.8842344284057617\n",
      "Epoch: 106 \tLoss: 0.883263885974884\n",
      "Epoch: 107 \tLoss: 0.882303774356842\n",
      "Epoch: 108 \tLoss: 0.8813546299934387\n",
      "Epoch: 109 \tLoss: 0.880415678024292\n",
      "Epoch: 110 \tLoss: 0.8794874548912048\n",
      "Epoch: 111 \tLoss: 0.878569483757019\n",
      "Epoch: 112 \tLoss: 0.8776612281799316\n",
      "Epoch: 113 \tLoss: 0.8767631649971008\n",
      "Epoch: 114 \tLoss: 0.8758747577667236\n",
      "Epoch: 115 \tLoss: 0.8749958276748657\n",
      "Epoch: 116 \tLoss: 0.8741261959075928\n",
      "Epoch: 117 \tLoss: 0.8732659816741943\n",
      "Epoch: 118 \tLoss: 0.8724147081375122\n",
      "Epoch: 119 \tLoss: 0.8715721964836121\n",
      "Epoch: 120 \tLoss: 0.8707386255264282\n",
      "Epoch: 121 \tLoss: 0.8699137568473816\n",
      "Epoch: 122 \tLoss: 0.8690968751907349\n",
      "Epoch: 123 \tLoss: 0.8682886958122253\n",
      "Epoch: 124 \tLoss: 0.8674882650375366\n",
      "Epoch: 125 \tLoss: 0.8666960000991821\n",
      "Epoch: 126 \tLoss: 0.8659115433692932\n",
      "Epoch: 127 \tLoss: 0.8651350140571594\n",
      "Epoch: 128 \tLoss: 0.8643659949302673\n",
      "Epoch: 129 \tLoss: 0.8636049628257751\n",
      "Epoch: 130 \tLoss: 0.8628520369529724\n",
      "Epoch: 131 \tLoss: 0.8621060848236084\n",
      "Epoch: 132 \tLoss: 0.8613674640655518\n",
      "Epoch: 133 \tLoss: 0.86063551902771\n",
      "Epoch: 134 \tLoss: 0.8599106073379517\n",
      "Epoch: 135 \tLoss: 0.859192430973053\n",
      "Epoch: 136 \tLoss: 0.8584805130958557\n",
      "Epoch: 137 \tLoss: 0.8577752709388733\n",
      "Epoch: 138 \tLoss: 0.8570764064788818\n",
      "Epoch: 139 \tLoss: 0.8563836216926575\n",
      "Epoch: 140 \tLoss: 0.8556976914405823\n",
      "Epoch: 141 \tLoss: 0.8550200462341309\n",
      "Epoch: 142 \tLoss: 0.8543484210968018\n",
      "Epoch: 143 \tLoss: 0.8536825180053711\n",
      "Epoch: 144 \tLoss: 0.8530222773551941\n",
      "Epoch: 145 \tLoss: 0.8523675799369812\n",
      "Epoch: 146 \tLoss: 0.851718544960022\n",
      "Epoch: 147 \tLoss: 0.8510752320289612\n",
      "Epoch: 148 \tLoss: 0.8504371643066406\n",
      "Epoch: 149 \tLoss: 0.8498044610023499\n",
      "Epoch: 150 \tLoss: 0.8491767644882202\n",
      "Epoch: 151 \tLoss: 0.848554253578186\n",
      "Epoch: 152 \tLoss: 0.8479400873184204\n",
      "Epoch: 153 \tLoss: 0.8473325371742249\n",
      "Epoch: 154 \tLoss: 0.8467295169830322\n",
      "Epoch: 155 \tLoss: 0.8461320400238037\n",
      "Epoch: 156 \tLoss: 0.8455392718315125\n",
      "Epoch: 157 \tLoss: 0.8449506759643555\n",
      "Epoch: 158 \tLoss: 0.844366729259491\n",
      "Epoch: 159 \tLoss: 0.8437879681587219\n",
      "Epoch: 160 \tLoss: 0.8432149291038513\n",
      "Epoch: 161 \tLoss: 0.8426461219787598\n",
      "Epoch: 162 \tLoss: 0.8420836329460144\n",
      "Epoch: 163 \tLoss: 0.8415251970291138\n",
      "Epoch: 164 \tLoss: 0.8409706354141235\n",
      "Epoch: 165 \tLoss: 0.840420126914978\n",
      "Epoch: 166 \tLoss: 0.8398734927177429\n",
      "Epoch: 167 \tLoss: 0.8393301963806152\n",
      "Epoch: 168 \tLoss: 0.8387895226478577\n",
      "Epoch: 169 \tLoss: 0.8382526636123657\n",
      "Epoch: 170 \tLoss: 0.8377196192741394\n",
      "Epoch: 171 \tLoss: 0.8371907472610474\n",
      "Epoch: 172 \tLoss: 0.8366649150848389\n",
      "Epoch: 173 \tLoss: 0.8361427187919617\n",
      "Epoch: 174 \tLoss: 0.8356237411499023\n",
      "Epoch: 175 \tLoss: 0.8351081013679504\n",
      "Epoch: 176 \tLoss: 0.8345959782600403\n",
      "Epoch: 177 \tLoss: 0.8340865969657898\n",
      "Epoch: 178 \tLoss: 0.8335805535316467\n",
      "Epoch: 179 \tLoss: 0.8330775499343872\n",
      "Epoch: 180 \tLoss: 0.8325774073600769\n",
      "Epoch: 181 \tLoss: 0.8320804238319397\n",
      "Epoch: 182 \tLoss: 0.8315861821174622\n",
      "Epoch: 183 \tLoss: 0.8310946226119995\n",
      "Epoch: 184 \tLoss: 0.8306058049201965\n",
      "Epoch: 185 \tLoss: 0.8301199078559875\n",
      "Epoch: 186 \tLoss: 0.8296365737915039\n",
      "Epoch: 187 \tLoss: 0.8291559815406799\n",
      "Epoch: 188 \tLoss: 0.8286779522895813\n",
      "Epoch: 189 \tLoss: 0.8282023072242737\n",
      "Epoch: 190 \tLoss: 0.8277300596237183\n",
      "Epoch: 191 \tLoss: 0.8272616863250732\n",
      "Epoch: 192 \tLoss: 0.8267953395843506\n",
      "Epoch: 193 \tLoss: 0.8263316750526428\n",
      "Epoch: 194 \tLoss: 0.8258703351020813\n",
      "Epoch: 195 \tLoss: 0.8254111409187317\n",
      "Epoch: 196 \tLoss: 0.8249542117118835\n",
      "Epoch: 197 \tLoss: 0.824499785900116\n",
      "Epoch: 198 \tLoss: 0.8240475058555603\n",
      "Epoch: 199 \tLoss: 0.8235976099967957\n",
      "Epoch: 200 \tLoss: 0.8231498599052429\n",
      "Epoch: 201 \tLoss: 0.8227041363716125\n",
      "Epoch: 202 \tLoss: 0.8222600221633911\n",
      "Epoch: 203 \tLoss: 0.8218182921409607\n",
      "Epoch: 204 \tLoss: 0.821378231048584\n",
      "Epoch: 205 \tLoss: 0.8209401369094849\n",
      "Epoch: 206 \tLoss: 0.8205040693283081\n",
      "Epoch: 207 \tLoss: 0.8200697898864746\n",
      "Epoch: 208 \tLoss: 0.8196372985839844\n",
      "Epoch: 209 \tLoss: 0.8192064166069031\n",
      "Epoch: 210 \tLoss: 0.8187774419784546\n",
      "Epoch: 211 \tLoss: 0.818350076675415\n",
      "Epoch: 212 \tLoss: 0.817924439907074\n",
      "Epoch: 213 \tLoss: 0.8175005316734314\n",
      "Epoch: 214 \tLoss: 0.8170779943466187\n",
      "Epoch: 215 \tLoss: 0.8166570663452148\n",
      "Epoch: 216 \tLoss: 0.8162378072738647\n",
      "Epoch: 217 \tLoss: 0.8158199787139893\n",
      "Epoch: 218 \tLoss: 0.8154038190841675\n",
      "Epoch: 219 \tLoss: 0.8149889707565308\n",
      "Epoch: 220 \tLoss: 0.8145753741264343\n",
      "Epoch: 221 \tLoss: 0.8141639828681946\n",
      "Epoch: 222 \tLoss: 0.8137540221214294\n",
      "Epoch: 223 \tLoss: 0.8133454322814941\n",
      "Epoch: 224 \tLoss: 0.8129387497901917\n",
      "Epoch: 225 \tLoss: 0.8125349879264832\n",
      "Epoch: 226 \tLoss: 0.8121341466903687\n",
      "Epoch: 227 \tLoss: 0.811734676361084\n",
      "Epoch: 228 \tLoss: 0.81133633852005\n",
      "Epoch: 229 \tLoss: 0.8109392523765564\n",
      "Epoch: 230 \tLoss: 0.8105438947677612\n",
      "Epoch: 231 \tLoss: 0.810149610042572\n",
      "Epoch: 232 \tLoss: 0.8097568154335022\n",
      "Epoch: 233 \tLoss: 0.8093643188476562\n",
      "Epoch: 234 \tLoss: 0.8089722394943237\n",
      "Epoch: 235 \tLoss: 0.8085812926292419\n",
      "Epoch: 236 \tLoss: 0.8081917762756348\n",
      "Epoch: 237 \tLoss: 0.8078051805496216\n",
      "Epoch: 238 \tLoss: 0.8074196577072144\n",
      "Epoch: 239 \tLoss: 0.807034969329834\n",
      "Epoch: 240 \tLoss: 0.8066516518592834\n",
      "Epoch: 241 \tLoss: 0.8062691688537598\n",
      "Epoch: 242 \tLoss: 0.805887758731842\n",
      "Epoch: 243 \tLoss: 0.805507481098175\n",
      "Epoch: 244 \tLoss: 0.8051283955574036\n",
      "Epoch: 245 \tLoss: 0.8047503232955933\n",
      "Epoch: 246 \tLoss: 0.804373025894165\n",
      "Epoch: 247 \tLoss: 0.8039968609809875\n",
      "Epoch: 248 \tLoss: 0.8036215901374817\n",
      "Epoch: 249 \tLoss: 0.8032471537590027\n",
      "Epoch: 250 \tLoss: 0.8028733730316162\n",
      "Epoch: 251 \tLoss: 0.8025009036064148\n",
      "Epoch: 252 \tLoss: 0.8021290302276611\n",
      "Epoch: 253 \tLoss: 0.8017584085464478\n",
      "Epoch: 254 \tLoss: 0.8013903498649597\n",
      "Epoch: 255 \tLoss: 0.8010226488113403\n",
      "Epoch: 256 \tLoss: 0.8006561398506165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 257 \tLoss: 0.8002903461456299\n",
      "Epoch: 258 \tLoss: 0.7999253869056702\n",
      "Epoch: 259 \tLoss: 0.799561083316803\n",
      "Epoch: 260 \tLoss: 0.7991977334022522\n",
      "Epoch: 261 \tLoss: 0.7988353967666626\n",
      "Epoch: 262 \tLoss: 0.7984734177589417\n",
      "Epoch: 263 \tLoss: 0.7981125116348267\n",
      "Epoch: 264 \tLoss: 0.797752320766449\n",
      "Epoch: 265 \tLoss: 0.7973927855491638\n",
      "Epoch: 266 \tLoss: 0.7970355749130249\n",
      "Epoch: 267 \tLoss: 0.7966790795326233\n",
      "Epoch: 268 \tLoss: 0.7963234782218933\n",
      "Epoch: 269 \tLoss: 0.7959684729576111\n",
      "Epoch: 270 \tLoss: 0.7956140041351318\n",
      "Epoch: 271 \tLoss: 0.7952601909637451\n",
      "Epoch: 272 \tLoss: 0.79490727186203\n",
      "Epoch: 273 \tLoss: 0.7945548295974731\n",
      "Epoch: 274 \tLoss: 0.7942032814025879\n",
      "Epoch: 275 \tLoss: 0.7938522100448608\n",
      "Epoch: 276 \tLoss: 0.7935018539428711\n",
      "Epoch: 277 \tLoss: 0.7931520938873291\n",
      "Epoch: 278 \tLoss: 0.7928027510643005\n",
      "Epoch: 279 \tLoss: 0.7924541234970093\n",
      "Epoch: 280 \tLoss: 0.792106032371521\n",
      "Epoch: 281 \tLoss: 0.7917584180831909\n",
      "Epoch: 282 \tLoss: 0.7914115786552429\n",
      "Epoch: 283 \tLoss: 0.7910652756690979\n",
      "Epoch: 284 \tLoss: 0.7907195091247559\n",
      "Epoch: 285 \tLoss: 0.790374219417572\n",
      "Epoch: 286 \tLoss: 0.7900295853614807\n",
      "Epoch: 287 \tLoss: 0.7896853089332581\n",
      "Epoch: 288 \tLoss: 0.7893417477607727\n",
      "Epoch: 289 \tLoss: 0.7889984846115112\n",
      "Epoch: 290 \tLoss: 0.7886559963226318\n",
      "Epoch: 291 \tLoss: 0.7883142232894897\n",
      "Epoch: 292 \tLoss: 0.7879729270935059\n",
      "Epoch: 293 \tLoss: 0.7876322269439697\n",
      "Epoch: 294 \tLoss: 0.7872918248176575\n",
      "Epoch: 295 \tLoss: 0.786952793598175\n",
      "Epoch: 296 \tLoss: 0.7866150140762329\n",
      "Epoch: 297 \tLoss: 0.7862775921821594\n",
      "Epoch: 298 \tLoss: 0.7859408855438232\n",
      "Epoch: 299 \tLoss: 0.7856053709983826\n",
      "Epoch: 300 \tLoss: 0.7852705121040344\n",
      "Epoch: 301 \tLoss: 0.7849360704421997\n",
      "Epoch: 302 \tLoss: 0.7846025824546814\n",
      "Epoch: 303 \tLoss: 0.7842695713043213\n",
      "Epoch: 304 \tLoss: 0.7839369177818298\n",
      "Epoch: 305 \tLoss: 0.783604621887207\n",
      "Epoch: 306 \tLoss: 0.7832732200622559\n",
      "Epoch: 307 \tLoss: 0.7829419374465942\n",
      "Epoch: 308 \tLoss: 0.7826114892959595\n",
      "Epoch: 309 \tLoss: 0.7822811603546143\n",
      "Epoch: 310 \tLoss: 0.7819515466690063\n",
      "Epoch: 311 \tLoss: 0.7816221714019775\n",
      "Epoch: 312 \tLoss: 0.7812932133674622\n",
      "Epoch: 313 \tLoss: 0.780964732170105\n",
      "Epoch: 314 \tLoss: 0.7806369066238403\n",
      "Epoch: 315 \tLoss: 0.7803090214729309\n",
      "Epoch: 316 \tLoss: 0.7799822688102722\n",
      "Epoch: 317 \tLoss: 0.779655396938324\n",
      "Epoch: 318 \tLoss: 0.7793290615081787\n",
      "Epoch: 319 \tLoss: 0.7790032029151917\n",
      "Epoch: 320 \tLoss: 0.7786781191825867\n",
      "Epoch: 321 \tLoss: 0.7783541083335876\n",
      "Epoch: 322 \tLoss: 0.7780304551124573\n",
      "Epoch: 323 \tLoss: 0.7777073383331299\n",
      "Epoch: 324 \tLoss: 0.7773846983909607\n",
      "Epoch: 325 \tLoss: 0.7770620584487915\n",
      "Epoch: 326 \tLoss: 0.7767403721809387\n",
      "Epoch: 327 \tLoss: 0.7764186263084412\n",
      "Epoch: 328 \tLoss: 0.7760974168777466\n",
      "Epoch: 329 \tLoss: 0.7757768630981445\n",
      "Epoch: 330 \tLoss: 0.775456428527832\n",
      "Epoch: 331 \tLoss: 0.7751364707946777\n",
      "Epoch: 332 \tLoss: 0.7748168110847473\n",
      "Epoch: 333 \tLoss: 0.7744977474212646\n",
      "Epoch: 334 \tLoss: 0.7741791605949402\n",
      "Epoch: 335 \tLoss: 0.7738608717918396\n",
      "Epoch: 336 \tLoss: 0.7735429406166077\n",
      "Epoch: 337 \tLoss: 0.7732254862785339\n",
      "Epoch: 338 \tLoss: 0.7729083299636841\n",
      "Epoch: 339 \tLoss: 0.7725915908813477\n",
      "Epoch: 340 \tLoss: 0.7722752690315247\n",
      "Epoch: 341 \tLoss: 0.7719593644142151\n",
      "Epoch: 342 \tLoss: 0.7716437578201294\n",
      "Epoch: 343 \tLoss: 0.7713285088539124\n",
      "Epoch: 344 \tLoss: 0.7710134983062744\n",
      "Epoch: 345 \tLoss: 0.770699143409729\n",
      "Epoch: 346 \tLoss: 0.7703850865364075\n",
      "Epoch: 347 \tLoss: 0.7700711488723755\n",
      "Epoch: 348 \tLoss: 0.769757866859436\n",
      "Epoch: 349 \tLoss: 0.7694447636604309\n",
      "Epoch: 350 \tLoss: 0.7691319584846497\n",
      "Epoch: 351 \tLoss: 0.7688198685646057\n",
      "Epoch: 352 \tLoss: 0.7685078382492065\n",
      "Epoch: 353 \tLoss: 0.7681962847709656\n",
      "Epoch: 354 \tLoss: 0.7678849697113037\n",
      "Epoch: 355 \tLoss: 0.7675740718841553\n",
      "Epoch: 356 \tLoss: 0.7672635316848755\n",
      "Epoch: 357 \tLoss: 0.7669531106948853\n",
      "Epoch: 358 \tLoss: 0.7666435241699219\n",
      "Epoch: 359 \tLoss: 0.7663339376449585\n",
      "Epoch: 360 \tLoss: 0.7660248875617981\n",
      "Epoch: 361 \tLoss: 0.7657161951065063\n",
      "Epoch: 362 \tLoss: 0.7654076218605042\n",
      "Epoch: 363 \tLoss: 0.7650995850563049\n",
      "Epoch: 364 \tLoss: 0.7647921442985535\n",
      "Epoch: 365 \tLoss: 0.7644845843315125\n",
      "Epoch: 366 \tLoss: 0.7641777992248535\n",
      "Epoch: 367 \tLoss: 0.7638710737228394\n",
      "Epoch: 368 \tLoss: 0.7635646462440491\n",
      "Epoch: 369 \tLoss: 0.7632586359977722\n",
      "Epoch: 370 \tLoss: 0.7629531025886536\n",
      "Epoch: 371 \tLoss: 0.7626477479934692\n",
      "Epoch: 372 \tLoss: 0.7623427510261536\n",
      "Epoch: 373 \tLoss: 0.7620381712913513\n",
      "Epoch: 374 \tLoss: 0.7617340087890625\n",
      "Epoch: 375 \tLoss: 0.7614300847053528\n",
      "Epoch: 376 \tLoss: 0.7611265182495117\n",
      "Epoch: 377 \tLoss: 0.7608233094215393\n",
      "Epoch: 378 \tLoss: 0.7605205178260803\n",
      "Epoch: 379 \tLoss: 0.7602181434631348\n",
      "Epoch: 380 \tLoss: 0.7599157691001892\n",
      "Epoch: 381 \tLoss: 0.759614109992981\n",
      "Epoch: 382 \tLoss: 0.7593125104904175\n",
      "Epoch: 383 \tLoss: 0.7590115666389465\n",
      "Epoch: 384 \tLoss: 0.7587106227874756\n",
      "Epoch: 385 \tLoss: 0.7584102153778076\n",
      "Epoch: 386 \tLoss: 0.7581102252006531\n",
      "Epoch: 387 \tLoss: 0.7578102946281433\n",
      "Epoch: 388 \tLoss: 0.7575109601020813\n",
      "Epoch: 389 \tLoss: 0.7572119235992432\n",
      "Epoch: 390 \tLoss: 0.7569131851196289\n",
      "Epoch: 391 \tLoss: 0.7566147446632385\n",
      "Epoch: 392 \tLoss: 0.7563167214393616\n",
      "Epoch: 393 \tLoss: 0.7560190558433533\n",
      "Epoch: 394 \tLoss: 0.7557216286659241\n",
      "Epoch: 395 \tLoss: 0.7554248571395874\n",
      "Epoch: 396 \tLoss: 0.7551281452178955\n",
      "Epoch: 397 \tLoss: 0.7548319697380066\n",
      "Epoch: 398 \tLoss: 0.7545358538627625\n",
      "Epoch: 399 \tLoss: 0.7542403340339661\n",
      "Epoch: 400 \tLoss: 0.7539450526237488\n",
      "Epoch: 401 \tLoss: 0.7536501288414001\n",
      "Epoch: 402 \tLoss: 0.7533555030822754\n",
      "Epoch: 403 \tLoss: 0.7530614137649536\n",
      "Epoch: 404 \tLoss: 0.7527674436569214\n",
      "Epoch: 405 \tLoss: 0.7524740695953369\n",
      "Epoch: 406 \tLoss: 0.752180814743042\n",
      "Epoch: 407 \tLoss: 0.7518882155418396\n",
      "Epoch: 408 \tLoss: 0.7515957951545715\n",
      "Epoch: 409 \tLoss: 0.7513035535812378\n",
      "Epoch: 410 \tLoss: 0.7510120868682861\n",
      "Epoch: 411 \tLoss: 0.7507205605506897\n",
      "Epoch: 412 \tLoss: 0.7504294514656067\n",
      "Epoch: 413 \tLoss: 0.7501389384269714\n",
      "Epoch: 414 \tLoss: 0.7498487830162048\n",
      "Epoch: 415 \tLoss: 0.7495587468147278\n",
      "Epoch: 416 \tLoss: 0.7492692470550537\n",
      "Epoch: 417 \tLoss: 0.748979926109314\n",
      "Epoch: 418 \tLoss: 0.7486911416053772\n",
      "Epoch: 419 \tLoss: 0.7484026551246643\n",
      "Epoch: 420 \tLoss: 0.7481145262718201\n",
      "Epoch: 421 \tLoss: 0.7478268146514893\n",
      "Epoch: 422 \tLoss: 0.7475393414497375\n",
      "Epoch: 423 \tLoss: 0.7472524046897888\n",
      "Epoch: 424 \tLoss: 0.7469655275344849\n",
      "Epoch: 425 \tLoss: 0.7466792464256287\n",
      "Epoch: 426 \tLoss: 0.7463933229446411\n",
      "Epoch: 427 \tLoss: 0.7461077570915222\n",
      "Epoch: 428 \tLoss: 0.745822548866272\n",
      "Epoch: 429 \tLoss: 0.7455378770828247\n",
      "Epoch: 430 \tLoss: 0.7452534437179565\n",
      "Epoch: 431 \tLoss: 0.744969367980957\n",
      "Epoch: 432 \tLoss: 0.744685709476471\n",
      "Epoch: 433 \tLoss: 0.7444022297859192\n",
      "Epoch: 434 \tLoss: 0.7441193461418152\n",
      "Epoch: 435 \tLoss: 0.7438366413116455\n",
      "Epoch: 436 \tLoss: 0.7435545921325684\n",
      "Epoch: 437 \tLoss: 0.7432727217674255\n",
      "Epoch: 438 \tLoss: 0.7429913878440857\n",
      "Epoch: 439 \tLoss: 0.7427103519439697\n",
      "Epoch: 440 \tLoss: 0.7424296736717224\n",
      "Epoch: 441 \tLoss: 0.7421494126319885\n",
      "Epoch: 442 \tLoss: 0.7418695092201233\n",
      "Epoch: 443 \tLoss: 0.7415900230407715\n",
      "Epoch: 444 \tLoss: 0.7413109540939331\n",
      "Epoch: 445 \tLoss: 0.7410324215888977\n",
      "Epoch: 446 \tLoss: 0.7407539486885071\n",
      "Epoch: 447 \tLoss: 0.740476131439209\n",
      "Epoch: 448 \tLoss: 0.7401984930038452\n",
      "Epoch: 449 \tLoss: 0.7399213910102844\n",
      "Epoch: 450 \tLoss: 0.7396447062492371\n",
      "Epoch: 451 \tLoss: 0.7393684387207031\n",
      "Epoch: 452 \tLoss: 0.7390925884246826\n",
      "Epoch: 453 \tLoss: 0.7388171553611755\n",
      "Epoch: 454 \tLoss: 0.7385419011116028\n",
      "Epoch: 455 \tLoss: 0.7382673621177673\n",
      "Epoch: 456 \tLoss: 0.7379930019378662\n",
      "Epoch: 457 \tLoss: 0.7377191185951233\n",
      "Epoch: 458 \tLoss: 0.7374458909034729\n",
      "Epoch: 459 \tLoss: 0.7371727824211121\n",
      "Epoch: 460 \tLoss: 0.736900269985199\n",
      "Epoch: 461 \tLoss: 0.7366279363632202\n",
      "Epoch: 462 \tLoss: 0.7363560795783997\n",
      "Epoch: 463 \tLoss: 0.7360848188400269\n",
      "Epoch: 464 \tLoss: 0.7358137965202332\n",
      "Epoch: 465 \tLoss: 0.7355432510375977\n",
      "Epoch: 466 \tLoss: 0.7352730631828308\n",
      "Epoch: 467 \tLoss: 0.7350034117698669\n",
      "Epoch: 468 \tLoss: 0.7347341179847717\n",
      "Epoch: 469 \tLoss: 0.7344653010368347\n",
      "Epoch: 470 \tLoss: 0.7341967821121216\n",
      "Epoch: 471 \tLoss: 0.7339286804199219\n",
      "Epoch: 472 \tLoss: 0.7336612343788147\n",
      "Epoch: 473 \tLoss: 0.7333940267562866\n",
      "Epoch: 474 \tLoss: 0.733127236366272\n",
      "Epoch: 475 \tLoss: 0.7328609228134155\n",
      "Epoch: 476 \tLoss: 0.7325950860977173\n",
      "Epoch: 477 \tLoss: 0.732329785823822\n",
      "Epoch: 478 \tLoss: 0.7320645451545715\n",
      "Epoch: 479 \tLoss: 0.7318000793457031\n",
      "Epoch: 480 \tLoss: 0.7315358519554138\n",
      "Epoch: 481 \tLoss: 0.7312726974487305\n",
      "Epoch: 482 \tLoss: 0.7310100793838501\n",
      "Epoch: 483 \tLoss: 0.7307478189468384\n",
      "Epoch: 484 \tLoss: 0.730486273765564\n",
      "Epoch: 485 \tLoss: 0.7302250266075134\n",
      "Epoch: 486 \tLoss: 0.7299642562866211\n",
      "Epoch: 487 \tLoss: 0.7297042012214661\n",
      "Epoch: 488 \tLoss: 0.7294444441795349\n",
      "Epoch: 489 \tLoss: 0.729185163974762\n",
      "Epoch: 490 \tLoss: 0.7289262413978577\n",
      "Epoch: 491 \tLoss: 0.7286679744720459\n",
      "Epoch: 492 \tLoss: 0.728410005569458\n",
      "Epoch: 493 \tLoss: 0.7281523942947388\n",
      "Epoch: 494 \tLoss: 0.7278954982757568\n",
      "Epoch: 495 \tLoss: 0.7276390194892883\n",
      "Epoch: 496 \tLoss: 0.7273828387260437\n",
      "Epoch: 497 \tLoss: 0.7271271347999573\n",
      "Epoch: 498 \tLoss: 0.7268717288970947\n",
      "Epoch: 499 \tLoss: 0.7266170978546143\n",
      "Epoch: 500 \tLoss: 0.7263627648353577\n",
      "Epoch: 501 \tLoss: 0.7261089086532593\n",
      "Epoch: 502 \tLoss: 0.7258554100990295\n",
      "Epoch: 503 \tLoss: 0.7256024479866028\n",
      "Epoch: 504 \tLoss: 0.725350022315979\n",
      "Epoch: 505 \tLoss: 0.7250978350639343\n",
      "Epoch: 506 \tLoss: 0.7248463034629822\n",
      "Epoch: 507 \tLoss: 0.7245951294898987\n",
      "Epoch: 508 \tLoss: 0.7243443727493286\n",
      "Epoch: 509 \tLoss: 0.7240942120552063\n",
      "Epoch: 510 \tLoss: 0.7238444685935974\n",
      "Epoch: 511 \tLoss: 0.7235952019691467\n",
      "Epoch: 512 \tLoss: 0.7233462929725647\n",
      "Epoch: 513 \tLoss: 0.7230979204177856\n",
      "Epoch: 514 \tLoss: 0.7228500247001648\n",
      "Epoch: 515 \tLoss: 0.7226024866104126\n",
      "Epoch: 516 \tLoss: 0.7223556637763977\n",
      "Epoch: 517 \tLoss: 0.722109317779541\n",
      "Epoch: 518 \tLoss: 0.7218633890151978\n",
      "Epoch: 519 \tLoss: 0.7216179966926575\n",
      "Epoch: 520 \tLoss: 0.7213729023933411\n",
      "Epoch: 521 \tLoss: 0.7211283445358276\n",
      "Epoch: 522 \tLoss: 0.720884382724762\n",
      "Epoch: 523 \tLoss: 0.7206408381462097\n",
      "Epoch: 524 \tLoss: 0.7203977704048157\n",
      "Epoch: 525 \tLoss: 0.7201550602912903\n",
      "Epoch: 526 \tLoss: 0.7199128866195679\n",
      "Epoch: 527 \tLoss: 0.7196711897850037\n",
      "Epoch: 528 \tLoss: 0.7194299697875977\n",
      "Epoch: 529 \tLoss: 0.7191891074180603\n",
      "Epoch: 530 \tLoss: 0.7189487814903259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 531 \tLoss: 0.7187090516090393\n",
      "Epoch: 532 \tLoss: 0.7184698581695557\n",
      "Epoch: 533 \tLoss: 0.7182309627532959\n",
      "Epoch: 534 \tLoss: 0.7179925441741943\n",
      "Epoch: 535 \tLoss: 0.717754602432251\n",
      "Epoch: 536 \tLoss: 0.7175171971321106\n",
      "Epoch: 537 \tLoss: 0.7172802686691284\n",
      "Epoch: 538 \tLoss: 0.7170438170433044\n",
      "Epoch: 539 \tLoss: 0.7168076634407043\n",
      "Epoch: 540 \tLoss: 0.7165720462799072\n",
      "Epoch: 541 \tLoss: 0.716337263584137\n",
      "Epoch: 542 \tLoss: 0.7161027789115906\n",
      "Epoch: 543 \tLoss: 0.7158685326576233\n",
      "Epoch: 544 \tLoss: 0.7156350016593933\n",
      "Epoch: 545 \tLoss: 0.7154019474983215\n",
      "Epoch: 546 \tLoss: 0.7151691913604736\n",
      "Epoch: 547 \tLoss: 0.7149370908737183\n",
      "Epoch: 548 \tLoss: 0.7147054076194763\n",
      "Epoch: 549 \tLoss: 0.7144741415977478\n",
      "Epoch: 550 \tLoss: 0.7142434120178223\n",
      "Epoch: 551 \tLoss: 0.7140132188796997\n",
      "Epoch: 552 \tLoss: 0.7137836217880249\n",
      "Epoch: 553 \tLoss: 0.713554322719574\n",
      "Epoch: 554 \tLoss: 0.7133253216743469\n",
      "Epoch: 555 \tLoss: 0.7130972146987915\n",
      "Epoch: 556 \tLoss: 0.7128695249557495\n",
      "Epoch: 557 \tLoss: 0.712642252445221\n",
      "Epoch: 558 \tLoss: 0.7124155759811401\n",
      "Epoch: 559 \tLoss: 0.7121891379356384\n",
      "Epoch: 560 \tLoss: 0.7119632959365845\n",
      "Epoch: 561 \tLoss: 0.7117382287979126\n",
      "Epoch: 562 \tLoss: 0.7115134596824646\n",
      "Epoch: 563 \tLoss: 0.7112894058227539\n",
      "Epoch: 564 \tLoss: 0.7110655307769775\n",
      "Epoch: 565 \tLoss: 0.7108423113822937\n",
      "Epoch: 566 \tLoss: 0.710619330406189\n",
      "Epoch: 567 \tLoss: 0.7103967070579529\n",
      "Epoch: 568 \tLoss: 0.7101747393608093\n",
      "Epoch: 569 \tLoss: 0.7099533081054688\n",
      "Epoch: 570 \tLoss: 0.709732174873352\n",
      "Epoch: 571 \tLoss: 0.7095115780830383\n",
      "Epoch: 572 \tLoss: 0.7092914581298828\n",
      "Epoch: 573 \tLoss: 0.709071934223175\n",
      "Epoch: 574 \tLoss: 0.7088528871536255\n",
      "Epoch: 575 \tLoss: 0.708634614944458\n",
      "Epoch: 576 \tLoss: 0.708416759967804\n",
      "Epoch: 577 \tLoss: 0.7081997394561768\n",
      "Epoch: 578 \tLoss: 0.7079830765724182\n",
      "Epoch: 579 \tLoss: 0.7077669501304626\n",
      "Epoch: 580 \tLoss: 0.7075514197349548\n",
      "Epoch: 581 \tLoss: 0.7073360681533813\n",
      "Epoch: 582 \tLoss: 0.7071215510368347\n",
      "Epoch: 583 \tLoss: 0.706907331943512\n",
      "Epoch: 584 \tLoss: 0.7066936492919922\n",
      "Epoch: 585 \tLoss: 0.7064804434776306\n",
      "Epoch: 586 \tLoss: 0.7062677145004272\n",
      "Epoch: 587 \tLoss: 0.7060555219650269\n",
      "Epoch: 588 \tLoss: 0.7058436870574951\n",
      "Epoch: 589 \tLoss: 0.7056325674057007\n",
      "Epoch: 590 \tLoss: 0.7054218053817749\n",
      "Epoch: 591 \tLoss: 0.7052115797996521\n",
      "Epoch: 592 \tLoss: 0.7050017714500427\n",
      "Epoch: 593 \tLoss: 0.7047925591468811\n",
      "Epoch: 594 \tLoss: 0.7045837640762329\n",
      "Epoch: 595 \tLoss: 0.7043754458427429\n",
      "Epoch: 596 \tLoss: 0.7041677832603455\n",
      "Epoch: 597 \tLoss: 0.7039604783058167\n",
      "Epoch: 598 \tLoss: 0.703753650188446\n",
      "Epoch: 599 \tLoss: 0.703547477722168\n",
      "Epoch: 600 \tLoss: 0.7033416032791138\n",
      "Epoch: 601 \tLoss: 0.7031363844871521\n",
      "Epoch: 602 \tLoss: 0.7029315233230591\n",
      "Epoch: 603 \tLoss: 0.7027272582054138\n",
      "Epoch: 604 \tLoss: 0.7025232315063477\n",
      "Epoch: 605 \tLoss: 0.7023199200630188\n",
      "Epoch: 606 \tLoss: 0.7021170854568481\n",
      "Epoch: 607 \tLoss: 0.7019144892692566\n",
      "Epoch: 608 \tLoss: 0.7017128467559814\n",
      "Epoch: 609 \tLoss: 0.7015113234519958\n",
      "Epoch: 610 \tLoss: 0.7013104557991028\n",
      "Epoch: 611 \tLoss: 0.7011100053787231\n",
      "Epoch: 612 \tLoss: 0.7009100317955017\n",
      "Epoch: 613 \tLoss: 0.7007107138633728\n",
      "Epoch: 614 \tLoss: 0.7005115747451782\n",
      "Epoch: 615 \tLoss: 0.7003132104873657\n",
      "Epoch: 616 \tLoss: 0.7001150846481323\n",
      "Epoch: 617 \tLoss: 0.6999176144599915\n",
      "Epoch: 618 \tLoss: 0.6997204422950745\n",
      "Epoch: 619 \tLoss: 0.6995238661766052\n",
      "Epoch: 620 \tLoss: 0.699327826499939\n",
      "Epoch: 621 \tLoss: 0.6991321444511414\n",
      "Epoch: 622 \tLoss: 0.698936939239502\n",
      "Epoch: 623 \tLoss: 0.6987424492835999\n",
      "Epoch: 624 \tLoss: 0.6985481977462769\n",
      "Epoch: 625 \tLoss: 0.6983543634414673\n",
      "Epoch: 626 \tLoss: 0.6981611251831055\n",
      "Epoch: 627 \tLoss: 0.6979684233665466\n",
      "Epoch: 628 \tLoss: 0.697776198387146\n",
      "Epoch: 629 \tLoss: 0.6975842118263245\n",
      "Epoch: 630 \tLoss: 0.6973928809165955\n",
      "Epoch: 631 \tLoss: 0.6972021460533142\n",
      "Epoch: 632 \tLoss: 0.6970117092132568\n",
      "Epoch: 633 \tLoss: 0.6968218684196472\n",
      "Epoch: 634 \tLoss: 0.696632444858551\n",
      "Epoch: 635 \tLoss: 0.6964436173439026\n",
      "Epoch: 636 \tLoss: 0.6962552666664124\n",
      "Epoch: 637 \tLoss: 0.6960672736167908\n",
      "Epoch: 638 \tLoss: 0.6958798766136169\n",
      "Epoch: 639 \tLoss: 0.6956928968429565\n",
      "Epoch: 640 \tLoss: 0.6955063939094543\n",
      "Epoch: 641 \tLoss: 0.6953203678131104\n",
      "Epoch: 642 \tLoss: 0.6951348185539246\n",
      "Epoch: 643 \tLoss: 0.6949496269226074\n",
      "Epoch: 644 \tLoss: 0.6947649717330933\n",
      "Epoch: 645 \tLoss: 0.6945807337760925\n",
      "Epoch: 646 \tLoss: 0.6943972110748291\n",
      "Epoch: 647 \tLoss: 0.6942138671875\n",
      "Epoch: 648 \tLoss: 0.6940311193466187\n",
      "Epoch: 649 \tLoss: 0.693848729133606\n",
      "Epoch: 650 \tLoss: 0.693666934967041\n",
      "Epoch: 651 \tLoss: 0.6934855580329895\n",
      "Epoch: 652 \tLoss: 0.6933045983314514\n",
      "Epoch: 653 \tLoss: 0.6931241154670715\n",
      "Epoch: 654 \tLoss: 0.6929441094398499\n",
      "Epoch: 655 \tLoss: 0.6927642822265625\n",
      "Epoch: 656 \tLoss: 0.6925852298736572\n",
      "Epoch: 657 \tLoss: 0.6924065351486206\n",
      "Epoch: 658 \tLoss: 0.6922282576560974\n",
      "Epoch: 659 \tLoss: 0.6920505166053772\n",
      "Epoch: 660 \tLoss: 0.6918730139732361\n",
      "Epoch: 661 \tLoss: 0.691696286201477\n",
      "Epoch: 662 \tLoss: 0.6915199160575867\n",
      "Epoch: 663 \tLoss: 0.6913439631462097\n",
      "Epoch: 664 \tLoss: 0.6911683678627014\n",
      "Epoch: 665 \tLoss: 0.6909933090209961\n",
      "Epoch: 666 \tLoss: 0.6908189058303833\n",
      "Epoch: 667 \tLoss: 0.6906446814537048\n",
      "Epoch: 668 \tLoss: 0.690470814704895\n",
      "Epoch: 669 \tLoss: 0.6902976036071777\n",
      "Epoch: 670 \tLoss: 0.6901248097419739\n",
      "Epoch: 671 \tLoss: 0.6899524927139282\n",
      "Epoch: 672 \tLoss: 0.6897805333137512\n",
      "Epoch: 673 \tLoss: 0.689609169960022\n",
      "Epoch: 674 \tLoss: 0.6894381046295166\n",
      "Epoch: 675 \tLoss: 0.6892674565315247\n",
      "Epoch: 676 \tLoss: 0.6890974044799805\n",
      "Epoch: 677 \tLoss: 0.6889277696609497\n",
      "Epoch: 678 \tLoss: 0.6887585520744324\n",
      "Epoch: 679 \tLoss: 0.6885896921157837\n",
      "Epoch: 680 \tLoss: 0.688421368598938\n",
      "Epoch: 681 \tLoss: 0.6882534623146057\n",
      "Epoch: 682 \tLoss: 0.6880860924720764\n",
      "Epoch: 683 \tLoss: 0.6879190802574158\n",
      "Epoch: 684 \tLoss: 0.6877524256706238\n",
      "Epoch: 685 \tLoss: 0.68758624792099\n",
      "Epoch: 686 \tLoss: 0.6874204874038696\n",
      "Epoch: 687 \tLoss: 0.6872552037239075\n",
      "Epoch: 688 \tLoss: 0.6870903968811035\n",
      "Epoch: 689 \tLoss: 0.6869258284568787\n",
      "Epoch: 690 \tLoss: 0.6867620348930359\n",
      "Epoch: 691 \tLoss: 0.6865983605384827\n",
      "Epoch: 692 \tLoss: 0.686435341835022\n",
      "Epoch: 693 \tLoss: 0.6862726807594299\n",
      "Epoch: 694 \tLoss: 0.6861104965209961\n",
      "Epoch: 695 \tLoss: 0.6859486699104309\n",
      "Epoch: 696 \tLoss: 0.6857873201370239\n",
      "Epoch: 697 \tLoss: 0.6856262683868408\n",
      "Epoch: 698 \tLoss: 0.6854658722877502\n",
      "Epoch: 699 \tLoss: 0.6853058338165283\n",
      "Epoch: 700 \tLoss: 0.6851460933685303\n",
      "Epoch: 701 \tLoss: 0.68498694896698\n",
      "Epoch: 702 \tLoss: 0.6848280429840088\n",
      "Epoch: 703 \tLoss: 0.6846697330474854\n",
      "Epoch: 704 \tLoss: 0.6845117211341858\n",
      "Epoch: 705 \tLoss: 0.6843542456626892\n",
      "Epoch: 706 \tLoss: 0.6841971278190613\n",
      "Epoch: 707 \tLoss: 0.6840406060218811\n",
      "Epoch: 708 \tLoss: 0.6838842034339905\n",
      "Epoch: 709 \tLoss: 0.6837283968925476\n",
      "Epoch: 710 \tLoss: 0.6835729479789734\n",
      "Epoch: 711 \tLoss: 0.6834180355072021\n",
      "Epoch: 712 \tLoss: 0.6832634210586548\n",
      "Epoch: 713 \tLoss: 0.6831093430519104\n",
      "Epoch: 714 \tLoss: 0.6829553246498108\n",
      "Epoch: 715 \tLoss: 0.6828020811080933\n",
      "Epoch: 716 \tLoss: 0.6826491951942444\n",
      "Epoch: 717 \tLoss: 0.6824967265129089\n",
      "Epoch: 718 \tLoss: 0.6823444366455078\n",
      "Epoch: 719 \tLoss: 0.6821926832199097\n",
      "Epoch: 720 \tLoss: 0.6820414066314697\n",
      "Epoch: 721 \tLoss: 0.6818904280662537\n",
      "Epoch: 722 \tLoss: 0.6817400455474854\n",
      "Epoch: 723 \tLoss: 0.6815899014472961\n",
      "Epoch: 724 \tLoss: 0.6814401745796204\n",
      "Epoch: 725 \tLoss: 0.6812907457351685\n",
      "Epoch: 726 \tLoss: 0.6811419725418091\n",
      "Epoch: 727 \tLoss: 0.680993378162384\n",
      "Epoch: 728 \tLoss: 0.680845320224762\n",
      "Epoch: 729 \tLoss: 0.6806975603103638\n",
      "Epoch: 730 \tLoss: 0.6805502772331238\n",
      "Epoch: 731 \tLoss: 0.6804032921791077\n",
      "Epoch: 732 \tLoss: 0.680256724357605\n",
      "Epoch: 733 \tLoss: 0.6801106929779053\n",
      "Epoch: 734 \tLoss: 0.6799648404121399\n",
      "Epoch: 735 \tLoss: 0.6798194646835327\n",
      "Epoch: 736 \tLoss: 0.679674506187439\n",
      "Epoch: 737 \tLoss: 0.6795297861099243\n",
      "Epoch: 738 \tLoss: 0.679385781288147\n",
      "Epoch: 739 \tLoss: 0.6792417764663696\n",
      "Epoch: 740 \tLoss: 0.6790986657142639\n",
      "Epoch: 741 \tLoss: 0.6789553165435791\n",
      "Epoch: 742 \tLoss: 0.6788127422332764\n",
      "Epoch: 743 \tLoss: 0.6786705851554871\n",
      "Epoch: 744 \tLoss: 0.6785286068916321\n",
      "Epoch: 745 \tLoss: 0.678386926651001\n",
      "Epoch: 746 \tLoss: 0.6782458424568176\n",
      "Epoch: 747 \tLoss: 0.6781050562858582\n",
      "Epoch: 748 \tLoss: 0.6779648065567017\n",
      "Epoch: 749 \tLoss: 0.6778247952461243\n",
      "Epoch: 750 \tLoss: 0.6776852011680603\n",
      "Epoch: 751 \tLoss: 0.6775459051132202\n",
      "Epoch: 752 \tLoss: 0.6774071455001831\n",
      "Epoch: 753 \tLoss: 0.6772685050964355\n",
      "Epoch: 754 \tLoss: 0.6771302819252014\n",
      "Epoch: 755 \tLoss: 0.6769927144050598\n",
      "Epoch: 756 \tLoss: 0.676855206489563\n",
      "Epoch: 757 \tLoss: 0.6767182350158691\n",
      "Epoch: 758 \tLoss: 0.6765815019607544\n",
      "Epoch: 759 \tLoss: 0.6764452457427979\n",
      "Epoch: 760 \tLoss: 0.6763094067573547\n",
      "Epoch: 761 \tLoss: 0.676173746585846\n",
      "Epoch: 762 \tLoss: 0.6760386824607849\n",
      "Epoch: 763 \tLoss: 0.6759037971496582\n",
      "Epoch: 764 \tLoss: 0.6757692694664001\n",
      "Epoch: 765 \tLoss: 0.6756353378295898\n",
      "Epoch: 766 \tLoss: 0.6755015254020691\n",
      "Epoch: 767 \tLoss: 0.6753681898117065\n",
      "Epoch: 768 \tLoss: 0.6752350926399231\n",
      "Epoch: 769 \tLoss: 0.6751025319099426\n",
      "Epoch: 770 \tLoss: 0.6749701499938965\n",
      "Epoch: 771 \tLoss: 0.6748382449150085\n",
      "Epoch: 772 \tLoss: 0.6747065782546997\n",
      "Epoch: 773 \tLoss: 0.6745753288269043\n",
      "Epoch: 774 \tLoss: 0.6744444370269775\n",
      "Epoch: 775 \tLoss: 0.6743139028549194\n",
      "Epoch: 776 \tLoss: 0.6741839051246643\n",
      "Epoch: 777 \tLoss: 0.6740538477897644\n",
      "Epoch: 778 \tLoss: 0.6739245653152466\n",
      "Epoch: 779 \tLoss: 0.6737953424453735\n",
      "Epoch: 780 \tLoss: 0.6736666560173035\n",
      "Epoch: 781 \tLoss: 0.6735381484031677\n",
      "Epoch: 782 \tLoss: 0.6734100580215454\n",
      "Epoch: 783 \tLoss: 0.673282265663147\n",
      "Epoch: 784 \tLoss: 0.6731548309326172\n",
      "Epoch: 785 \tLoss: 0.673027753829956\n",
      "Epoch: 786 \tLoss: 0.6729012131690979\n",
      "Epoch: 787 \tLoss: 0.672774612903595\n",
      "Epoch: 788 \tLoss: 0.6726487278938293\n",
      "Epoch: 789 \tLoss: 0.6725229620933533\n",
      "Epoch: 790 \tLoss: 0.6723975539207458\n",
      "Epoch: 791 \tLoss: 0.6722726821899414\n",
      "Epoch: 792 \tLoss: 0.6721482276916504\n",
      "Epoch: 793 \tLoss: 0.6720235347747803\n",
      "Epoch: 794 \tLoss: 0.671899676322937\n",
      "Epoch: 795 \tLoss: 0.6717758774757385\n",
      "Epoch: 796 \tLoss: 0.6716525554656982\n",
      "Epoch: 797 \tLoss: 0.6715296506881714\n",
      "Epoch: 798 \tLoss: 0.6714068651199341\n",
      "Epoch: 799 \tLoss: 0.671284556388855\n",
      "Epoch: 800 \tLoss: 0.6711626052856445\n",
      "Epoch: 801 \tLoss: 0.6710408329963684\n",
      "Epoch: 802 \tLoss: 0.6709194779396057\n",
      "Epoch: 803 \tLoss: 0.6707985401153564\n",
      "Epoch: 804 \tLoss: 0.6706777215003967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 805 \tLoss: 0.6705573797225952\n",
      "Epoch: 806 \tLoss: 0.6704372763633728\n",
      "Epoch: 807 \tLoss: 0.6703174710273743\n",
      "Epoch: 808 \tLoss: 0.6701981425285339\n",
      "Epoch: 809 \tLoss: 0.6700791120529175\n",
      "Epoch: 810 \tLoss: 0.6699602603912354\n",
      "Epoch: 811 \tLoss: 0.6698418259620667\n",
      "Epoch: 812 \tLoss: 0.6697236895561218\n",
      "Epoch: 813 \tLoss: 0.6696059107780457\n",
      "Epoch: 814 \tLoss: 0.6694883704185486\n",
      "Epoch: 815 \tLoss: 0.6693711876869202\n",
      "Epoch: 816 \tLoss: 0.6692543625831604\n",
      "Epoch: 817 \tLoss: 0.669137716293335\n",
      "Epoch: 818 \tLoss: 0.6690215468406677\n",
      "Epoch: 819 \tLoss: 0.6689054369926453\n",
      "Epoch: 820 \tLoss: 0.6687899827957153\n",
      "Epoch: 821 \tLoss: 0.6686747074127197\n",
      "Epoch: 822 \tLoss: 0.6685595512390137\n",
      "Epoch: 823 \tLoss: 0.6684448719024658\n",
      "Epoch: 824 \tLoss: 0.6683304905891418\n",
      "Epoch: 825 \tLoss: 0.668216347694397\n",
      "Epoch: 826 \tLoss: 0.6681026220321655\n",
      "Epoch: 827 \tLoss: 0.6679892539978027\n",
      "Epoch: 828 \tLoss: 0.667876124382019\n",
      "Epoch: 829 \tLoss: 0.6677632927894592\n",
      "Epoch: 830 \tLoss: 0.6676508784294128\n",
      "Epoch: 831 \tLoss: 0.6675387620925903\n",
      "Epoch: 832 \tLoss: 0.6674268245697021\n",
      "Epoch: 833 \tLoss: 0.6673153638839722\n",
      "Epoch: 834 \tLoss: 0.667203962802887\n",
      "Epoch: 835 \tLoss: 0.6670929193496704\n",
      "Epoch: 836 \tLoss: 0.666982114315033\n",
      "Epoch: 837 \tLoss: 0.6668717265129089\n",
      "Epoch: 838 \tLoss: 0.6667618155479431\n",
      "Epoch: 839 \tLoss: 0.6666519641876221\n",
      "Epoch: 840 \tLoss: 0.6665422916412354\n",
      "Epoch: 841 \tLoss: 0.6664331555366516\n",
      "Epoch: 842 \tLoss: 0.6663240790367126\n",
      "Epoch: 843 \tLoss: 0.6662155389785767\n",
      "Epoch: 844 \tLoss: 0.666107177734375\n",
      "Epoch: 845 \tLoss: 0.6659990549087524\n",
      "Epoch: 846 \tLoss: 0.6658914089202881\n",
      "Epoch: 847 \tLoss: 0.6657838821411133\n",
      "Epoch: 848 \tLoss: 0.6656766533851624\n",
      "Epoch: 849 \tLoss: 0.6655696034431458\n",
      "Epoch: 850 \tLoss: 0.6654630303382874\n",
      "Epoch: 851 \tLoss: 0.6653566360473633\n",
      "Epoch: 852 \tLoss: 0.6652507185935974\n",
      "Epoch: 853 \tLoss: 0.6651448607444763\n",
      "Epoch: 854 \tLoss: 0.6650393009185791\n",
      "Epoch: 855 \tLoss: 0.6649340987205505\n",
      "Epoch: 856 \tLoss: 0.6648290157318115\n",
      "Epoch: 857 \tLoss: 0.6647242903709412\n",
      "Epoch: 858 \tLoss: 0.6646199822425842\n",
      "Epoch: 859 \tLoss: 0.6645157933235168\n",
      "Epoch: 860 \tLoss: 0.6644119620323181\n",
      "Epoch: 861 \tLoss: 0.6643083691596985\n",
      "Epoch: 862 \tLoss: 0.6642049551010132\n",
      "Epoch: 863 \tLoss: 0.6641020178794861\n",
      "Epoch: 864 \tLoss: 0.6639991998672485\n",
      "Epoch: 865 \tLoss: 0.6638966798782349\n",
      "Epoch: 866 \tLoss: 0.6637945175170898\n",
      "Epoch: 867 \tLoss: 0.6636925339698792\n",
      "Epoch: 868 \tLoss: 0.6635908484458923\n",
      "Epoch: 869 \tLoss: 0.6634894609451294\n",
      "Epoch: 870 \tLoss: 0.6633882522583008\n",
      "Epoch: 871 \tLoss: 0.6632874608039856\n",
      "Epoch: 872 \tLoss: 0.66318678855896\n",
      "Epoch: 873 \tLoss: 0.6630862951278687\n",
      "Epoch: 874 \tLoss: 0.6629863381385803\n",
      "Epoch: 875 \tLoss: 0.6628865003585815\n",
      "Epoch: 876 \tLoss: 0.6627867817878723\n",
      "Epoch: 877 \tLoss: 0.6626875400543213\n",
      "Epoch: 878 \tLoss: 0.6625886559486389\n",
      "Epoch: 879 \tLoss: 0.6624897718429565\n",
      "Epoch: 880 \tLoss: 0.662391185760498\n",
      "Epoch: 881 \tLoss: 0.6622928977012634\n",
      "Epoch: 882 \tLoss: 0.6621949672698975\n",
      "Epoch: 883 \tLoss: 0.6620970964431763\n",
      "Epoch: 884 \tLoss: 0.6619995832443237\n",
      "Epoch: 885 \tLoss: 0.6619023680686951\n",
      "Epoch: 886 \tLoss: 0.6618055701255798\n",
      "Epoch: 887 \tLoss: 0.661708652973175\n",
      "Epoch: 888 \tLoss: 0.6616121530532837\n",
      "Epoch: 889 \tLoss: 0.6615158319473267\n",
      "Epoch: 890 \tLoss: 0.6614198684692383\n",
      "Epoch: 891 \tLoss: 0.6613243222236633\n",
      "Epoch: 892 \tLoss: 0.6612287163734436\n",
      "Epoch: 893 \tLoss: 0.6611334681510925\n",
      "Epoch: 894 \tLoss: 0.6610383987426758\n",
      "Epoch: 895 \tLoss: 0.6609438061714172\n",
      "Epoch: 896 \tLoss: 0.6608492732048035\n",
      "Epoch: 897 \tLoss: 0.6607549786567688\n",
      "Epoch: 898 \tLoss: 0.6606608629226685\n",
      "Epoch: 899 \tLoss: 0.6605672836303711\n",
      "Epoch: 900 \tLoss: 0.6604735255241394\n",
      "Epoch: 901 \tLoss: 0.6603803634643555\n",
      "Epoch: 902 \tLoss: 0.6602872610092163\n",
      "Epoch: 903 \tLoss: 0.6601946353912354\n",
      "Epoch: 904 \tLoss: 0.6601020693778992\n",
      "Epoch: 905 \tLoss: 0.6600098013877869\n",
      "Epoch: 906 \tLoss: 0.6599176526069641\n",
      "Epoch: 907 \tLoss: 0.6598257422447205\n",
      "Epoch: 908 \tLoss: 0.6597341895103455\n",
      "Epoch: 909 \tLoss: 0.6596428155899048\n",
      "Epoch: 910 \tLoss: 0.6595515608787537\n",
      "Epoch: 911 \tLoss: 0.6594607830047607\n",
      "Epoch: 912 \tLoss: 0.6593700647354126\n",
      "Epoch: 913 \tLoss: 0.6592797040939331\n",
      "Epoch: 914 \tLoss: 0.6591894626617432\n",
      "Epoch: 915 \tLoss: 0.6590995192527771\n",
      "Epoch: 916 \tLoss: 0.6590097546577454\n",
      "Epoch: 917 \tLoss: 0.6589202284812927\n",
      "Epoch: 918 \tLoss: 0.6588309407234192\n",
      "Epoch: 919 \tLoss: 0.6587419509887695\n",
      "Epoch: 920 \tLoss: 0.6586530804634094\n",
      "Epoch: 921 \tLoss: 0.658564567565918\n",
      "Epoch: 922 \tLoss: 0.6584761738777161\n",
      "Epoch: 923 \tLoss: 0.6583880186080933\n",
      "Epoch: 924 \tLoss: 0.6583000421524048\n",
      "Epoch: 925 \tLoss: 0.6582125425338745\n",
      "Epoch: 926 \tLoss: 0.6581249237060547\n",
      "Epoch: 927 \tLoss: 0.6580377221107483\n",
      "Epoch: 928 \tLoss: 0.6579506993293762\n",
      "Epoch: 929 \tLoss: 0.657863974571228\n",
      "Epoch: 930 \tLoss: 0.6577773094177246\n",
      "Epoch: 931 \tLoss: 0.6576911211013794\n",
      "Epoch: 932 \tLoss: 0.6576048731803894\n",
      "Epoch: 933 \tLoss: 0.6575189828872681\n",
      "Epoch: 934 \tLoss: 0.6574330925941467\n",
      "Epoch: 935 \tLoss: 0.6573477983474731\n",
      "Epoch: 936 \tLoss: 0.6572626233100891\n",
      "Epoch: 937 \tLoss: 0.6571775078773499\n",
      "Epoch: 938 \tLoss: 0.6570926904678345\n",
      "Epoch: 939 \tLoss: 0.6570080518722534\n",
      "Epoch: 940 \tLoss: 0.6569236516952515\n",
      "Epoch: 941 \tLoss: 0.6568396091461182\n",
      "Epoch: 942 \tLoss: 0.6567553877830505\n",
      "Epoch: 943 \tLoss: 0.6566717028617859\n",
      "Epoch: 944 \tLoss: 0.6565881371498108\n",
      "Epoch: 945 \tLoss: 0.6565049290657043\n",
      "Epoch: 946 \tLoss: 0.6564216613769531\n",
      "Epoch: 947 \tLoss: 0.6563388109207153\n",
      "Epoch: 948 \tLoss: 0.6562560796737671\n",
      "Epoch: 949 \tLoss: 0.6561735272407532\n",
      "Epoch: 950 \tLoss: 0.6560913920402527\n",
      "Epoch: 951 \tLoss: 0.656009316444397\n",
      "Epoch: 952 \tLoss: 0.6559274196624756\n",
      "Epoch: 953 \tLoss: 0.6558457016944885\n",
      "Epoch: 954 \tLoss: 0.6557641625404358\n",
      "Epoch: 955 \tLoss: 0.6556829214096069\n",
      "Epoch: 956 \tLoss: 0.6556019186973572\n",
      "Epoch: 957 \tLoss: 0.6555211544036865\n",
      "Epoch: 958 \tLoss: 0.6554404497146606\n",
      "Epoch: 959 \tLoss: 0.6553599834442139\n",
      "Epoch: 960 \tLoss: 0.655279815196991\n",
      "Epoch: 961 \tLoss: 0.6551997661590576\n",
      "Epoch: 962 \tLoss: 0.6551198959350586\n",
      "Epoch: 963 \tLoss: 0.6550403237342834\n",
      "Epoch: 964 \tLoss: 0.6549607515335083\n",
      "Epoch: 965 \tLoss: 0.6548813581466675\n",
      "Epoch: 966 \tLoss: 0.6548024415969849\n",
      "Epoch: 967 \tLoss: 0.654723584651947\n",
      "Epoch: 968 \tLoss: 0.6546449661254883\n",
      "Epoch: 969 \tLoss: 0.6545664668083191\n",
      "Epoch: 970 \tLoss: 0.6544882655143738\n",
      "Epoch: 971 \tLoss: 0.6544100046157837\n",
      "Epoch: 972 \tLoss: 0.6543323993682861\n",
      "Epoch: 973 \tLoss: 0.6542544364929199\n",
      "Epoch: 974 \tLoss: 0.6541771292686462\n",
      "Epoch: 975 \tLoss: 0.6540997624397278\n",
      "Epoch: 976 \tLoss: 0.6540226936340332\n",
      "Epoch: 977 \tLoss: 0.653945803642273\n",
      "Epoch: 978 \tLoss: 0.653869092464447\n",
      "Epoch: 979 \tLoss: 0.6537926197052002\n",
      "Epoch: 980 \tLoss: 0.6537162065505981\n",
      "Epoch: 981 \tLoss: 0.6536400318145752\n",
      "Epoch: 982 \tLoss: 0.6535640954971313\n",
      "Epoch: 983 \tLoss: 0.6534882187843323\n",
      "Epoch: 984 \tLoss: 0.6534126996994019\n",
      "Epoch: 985 \tLoss: 0.6533371210098267\n",
      "Epoch: 986 \tLoss: 0.6532620191574097\n",
      "Epoch: 987 \tLoss: 0.653187096118927\n",
      "Epoch: 988 \tLoss: 0.6531121730804443\n",
      "Epoch: 989 \tLoss: 0.6530374884605408\n",
      "Epoch: 990 \tLoss: 0.6529629826545715\n",
      "Epoch: 991 \tLoss: 0.652888834476471\n",
      "Epoch: 992 \tLoss: 0.6528146266937256\n",
      "Epoch: 993 \tLoss: 0.6527407169342041\n",
      "Epoch: 994 \tLoss: 0.6526669263839722\n",
      "Epoch: 995 \tLoss: 0.6525934338569641\n",
      "Epoch: 996 \tLoss: 0.652519941329956\n",
      "Epoch: 997 \tLoss: 0.6524468064308167\n",
      "Epoch: 998 \tLoss: 0.6523739099502563\n",
      "Epoch: 999 \tLoss: 0.6523008942604065\n"
     ]
    }
   ],
   "source": [
    "classifier = Network()\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = classifier(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch:', epoch, '\\tLoss:', loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy 0.9809523809523809\n"
     ]
    }
   ],
   "source": [
    "predict_out = classifier(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print('prediction accuracy', accuracy_score(test_y.data, predict_y.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
